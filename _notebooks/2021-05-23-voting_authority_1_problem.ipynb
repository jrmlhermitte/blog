{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Predicting Linked Social Media Accounts\n",
    "> \"This blog post attempts to walk through computing the precision of from a range of possibly imprecise scrapers/classifiers.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n",
    "- hide: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the overwhelming amount of information out there,\n",
    "it is sometimes hard to find what one is looking for.\n",
    "For every few true sources, there are often incorrect ones.\n",
    "\n",
    "# Example Case: A Social Media Finder\n",
    "This kind of scenario can often be found in web scraping.\n",
    "Let's look at a simple example of a \"social media finder\".\n",
    "Let's say, we have lists of hundreds of thousands of domains,\n",
    "and we want to see if we can find linked social media accounts?\n",
    "\n",
    "It turns out, there is a practical way of determining this which can\n",
    "often lead to simplifying the understanding of the correctness of\n",
    "knowledgegraphs that one develops, and I'd like to show you how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Media Finder Example\n",
    "Let's say, for example, you have some hypotheses of potential twitter accounts for a certain domain, `cnn.com`, one `@CNN` and the other `@JohnDoe`. How do you know if they are right or wrong?\n",
    "\n",
    "<img src=\"images/2021_05_24_cnn_example_1.png\" alt=\"CNN Example\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in these cases, one will seek for help from multiple sources to get this answer right. And often, these sources will be correct a certain percentage of the time:\n",
    "\n",
    "\n",
    "<img src=\"images/2021_05_24_cnn_example_2.png\" alt=\"CNN Example\" width=\"400\"/>\n",
    "\n",
    "Such a scenario can be common not only in automated scrapers, but even situations such as knowledge graphs, where the \"classifier\" is actually a human."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Media Finder Example: Some numbers\n",
    "In order to better understand how to tackle this problem,\n",
    "let's look at a specific example.\n",
    "\n",
    "Let's say you have a bunch of social media finders \n",
    "trying to figure out what social media accounts \n",
    "are connected to `cnn.com` and that you have two\n",
    "that have found `@CNN` to be \n",
    "related {% fn 1 %}:\n",
    "- method 1 uses some other independent technique and\n",
    "  is right **65%** of the time for correct values.\n",
    "- method 2 uses a knowledgegraph and is right **80%** of the time\n",
    "\n",
    "And one method that has not found this relation to be true:\n",
    "- method 3 uses some scraping technique. Although it has not detected\n",
    "anything, it has a False negative rate of **60%** (**60%** of the accounts\n",
    "it fails to link it is wrong about).\n",
    "\n",
    "<img src=\"images/2021_05_24_cnn_example_3.png\" alt=\"CNN Example\" width=\"400\"/>\n",
    "\n",
    "What would be this combined precision?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get to this will take a bit of work, and I will walk you through it.\n",
    "\n",
    "But to get a feel for what the answer would look like, I will give you a small preview. The answer to this problem should be:\n",
    "$$.65 * .8 * .6 / (.65 * .8 * .6 + (1-.65)*(1-.8)*(1-.6) \\approx 91.8%$$\n",
    "That's **91.8%**!!!! That's quite jump in confidence.\n",
    "\n",
    "Before I continue to explain this result, here is the same formula in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "def combined_p(precisions_or_fpr: List[float]):\n",
    "    \"\"\"Compute the combined precision_or_fpr from multiple authorities.\"\"\"\n",
    "    if not precisions_or_fpr:\n",
    "        return 0\n",
    "    product = 1\n",
    "    product_i = 1\n",
    "    for precision_or_fpr in precisions_or_fpr:\n",
    "        product *= precision_or_fpr\n",
    "        product_i *= (1. - precision_or_fpr)\n",
    "    return product / (product + product_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our test case above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176470588235295"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, the first two quantities are precisions and the last false positives\n",
    "combined_p([0.65, .8, .6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we get to this?\n",
    "\n",
    "In order to explain this, I will first go through some definitions\n",
    "and give the answer. I will then simulate a simple two system\n",
    "classifier to qualitatively validate the assumption. We will\n",
    "then validate whether this formula above is the right solution.\n",
    "\n",
    "The proof will be left for a later post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "We will define for any link being determined (ex: `@CNN` is a twitter user for `cnn.com`) as it being `True` if the link exists and `False` otherwise.\n",
    "\n",
    "We can define their confidence via their precision $Pr$:\n",
    "$$Pr = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "Where $TP$ stands for True Positives: the times something actually \n",
    "True was also classified True (\"Positive\") by the classifier. $FP$ stands for \n",
    "False positive, and finally $FN$ and $TN$ stand for false negative and \n",
    "true negative.\n",
    "\n",
    "We will also need to know their false negative rate. This is needed\n",
    "when the authority we are using does not think the link exists:\n",
    "$$FNR = \\frac{FN}{FN + TP}$$\n",
    "\n",
    "## Problem Statement\n",
    "> Given a set of  authorities and measured precision, \n",
    "where some classify an item as positive and some negative, \n",
    "what is the combined precision that this item is \n",
    "likely postive? We also assume here that all \n",
    "authorities are **independent**. {% fn 2 %}\n",
    "\n",
    "\n",
    "It turns out if you make the independence assumption, \n",
    "that there is a very simple answer. Say we have a set of authorities.\n",
    "For each of these $A_i$, they either classified an item as positive or not.\n",
    "Let's say that the set of all authorities that classified an item\n",
    "as positive is $\\bf{A}^+$. So authorities that classified \n",
    "an item as positive belong to this set: $A_i \\in \\bf{A}^+$.\n",
    "Conversely, authorities that did not classify an item as positive\n",
    "do not belong to $\\bf{A}^+$: $A_i \\notin \\bf{A}^+$.\n",
    "For each authority $A_i$, we measure their precision as $PR_i$\n",
    "and false negative rate $FNR_i$. Considering this\n",
    "notation, the combined precision would be:\n",
    "\n",
    "\n",
    "$$Pr_{combined} = \\frac{\\prod_{i \\in \\bf{A}^+} Pr_i \\prod_{j \\notin \\bf{A}^+} FNR_j}\n",
    "{\\prod_{i \\in \\bf{A}^+} Pr_i\\prod_{j \\notin \\bf{A}^+} FNR_j + \\prod_{i \\in \\bf{A}^+} (1 - Pr_i)\\prod_{j \\notin \\bf{A}^+} (1 - FNR_j)}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating an Authority with a Model\n",
    "Let's call these extractors authorities.\n",
    "\n",
    "We want to validate the formula stated above, so let's try\n",
    "simulating three authorities, compute their precisions and\n",
    "finally compute their combined precision both from data\n",
    "and the formula stated above.\n",
    "\n",
    "We can model an authority by its recall $Re$ and false positive rate $FPR$:\n",
    "\n",
    "$$Re = \\frac{TP}{T} =  \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$FPR = \\frac{FP}{F} = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "We then will simulate the decision of an authority for a set\n",
    "of possibilities with a known ground truth. When the ground \n",
    "truth is True, the probability of the authority reporting \n",
    "True will be the recall rate. When the ground truth is \n",
    "False, the probability of the authority reporting True \n",
    "is $(1- FPR)$ (or the probability of reporting false is \n",
    "the false positive rate $FPR$).\n",
    "\n",
    "\n",
    "Let's now represent this authority with a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Authority:\n",
    "    def __init__(self, recall: float, fpr: float):\n",
    "        self.recall = recall\n",
    "        self.fpr = fpr\n",
    "        \n",
    "    def __call__(self, actual_value: bool) -> bool:\n",
    "        \"\"\"\n",
    "        Here is our simulated authority.\n",
    "        We give it the actual value for simulation purposes.\n",
    "        \n",
    "        If the value is true, we only predict that it is true\n",
    "        in accordance with its recall.\n",
    "        If the value is false, we accidentally predict it is \n",
    "        true in accordance with its False positive rate.\n",
    "        \"\"\"\n",
    "        if actual_value is True:\n",
    "            if np.random.random() <= self.recall:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if np.random.random() <= self.fpr:\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's create three simple authorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authority 1 has a low recall but a very low false positive rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = Authority(recall=.3, fpr=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authority 2 has a high recall but a worse false positive rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = Authority(recall=.7, fpr=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authority 3 has low recall but fairly high false positive rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = Authority(recall=.1, fpr=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question here is that, if two independent authorities measure a positive and a third a negative, what is the probability that we have a positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a training set where we will run our comparisons.\n",
    "Let's run on 1000000 cases, and to make things closer to real world examples, \n",
    "let's introduce a bias of 80% toward False as such scenarios are quite\n",
    "common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "N_samples = 1000000\n",
    "# bias towards false values\n",
    "bias = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "measurements = []\n",
    "for _ in range(N_samples):\n",
    "    actual_value = bool(np.random.random() > bias)\n",
    "    \n",
    "    decision_a1 = a1(actual_value)\n",
    "    decision_a2 = a2(actual_value)\n",
    "    decision_a3 = a3(actual_value)\n",
    "    measurement = {\n",
    "        'actual': actual_value,\n",
    "        'a1': decision_a1,\n",
    "        'a2': decision_a2,\n",
    "        'a3': decision_a3,\n",
    "    }\n",
    "    measurements.append(measurement)\n",
    "    \n",
    "    \n",
    "# Let's combine our results into a dataframe to make things easier to visualize:\n",
    "df = pd.DataFrame(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual     a1     a2     a3\n",
       "0        False  False   True   True\n",
       "1        False  False  False   True\n",
       "2        False  False  False  False\n",
       "3        False  False  False  False\n",
       "4        False  False  False   True\n",
       "...        ...    ...    ...    ...\n",
       "999995   False  False  False   True\n",
       "999996   False  False   True   True\n",
       "999997   False  False   True   True\n",
       "999998   False  False  False  False\n",
       "999999   False  False  False  False\n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The measurements\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I mentioned we have a bias. If we want to measure the true precision, \n",
    "we have to make sure to account for this bias by resampling \n",
    "from our training set an equal number of actually true and false\n",
    "values. It is a bit silly to have introduced a bias in the \n",
    "first place from simulated data if we are just going to \n",
    "remove it. But this something that can be easily overlooked \n",
    "and is always worthwhile considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of samples, 200995 are true and 799005 are false.\n",
      "We choose to keep 200995 of true and false cases.\n"
     ]
    }
   ],
   "source": [
    "# Filter dataframe to actually true and false cases\n",
    "df_true = df[df['actual']]\n",
    "df_false = df[~df['actual']]\n",
    "# count them\n",
    "number_actually_true = len(df_true)\n",
    "number_actually_false = len(df_false)\n",
    "\n",
    "# choose smallest number as sampling number\n",
    "number_to_sample = min(number_actually_true, number_actually_false)\n",
    "\n",
    "print(f'Of samples, {number_actually_true} are true and {number_actually_false} are false.')\n",
    "print(f'We choose to keep {number_to_sample} of true and false cases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we reduce the dataset to a sampled dataset:\n",
    "df_sampled = pd.concat(\n",
    "    (\n",
    "        df_true.sample(number_to_sample),\n",
    "        df_false.sample(number_to_sample),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Combined Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the precision of A1 and A2 and verify the false negative rate of A3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of A1 is 0.7510203575283158\n"
     ]
    }
   ],
   "source": [
    "# Precision of A1\n",
    "prec_a1 = df_sampled[df_sampled['a1']]['actual'].mean()\n",
    "print(f'The precision of A1 is {prec_a1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of A2 is 0.6346139096302646\n"
     ]
    }
   ],
   "source": [
    "# Precision of A2\n",
    "prec_a2 = df_sampled[df_sampled['a2']]['actual'].mean()\n",
    "print(f'The precision of A2 is {prec_a2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fnr of A3 is 0.6425435872685785\n"
     ]
    }
   ],
   "source": [
    "# False negative rate of A3\n",
    "fnr_a3 = df_sampled[~df_sampled['a3']]['actual'].mean()\n",
    "print(f'The fnr of A3 is {fnr_a3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take the samples where A1 and A2 voted for a reference but A3 did not and count the precision of these two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of A1 and A2 given A3 did not classify is 0.9027603364530269\n",
      "This was measured over 42205 measurements.\n"
     ]
    }
   ],
   "source": [
    "# Precision of A1 and A2 voting\n",
    "prec_a1a2_not_a3 = df_sampled[df_sampled['a1'] & df_sampled['a2'] & ~df_sampled['a3']]['actual'].mean()\n",
    "matching_rows = len(df_sampled[df_sampled['a1'] & df_sampled['a2'] & ~df_sampled['a3']])\n",
    "print(f'The precision of A1 and A2 given A3 did not classify is {prec_a1a2_not_a3}')\n",
    "print(f'This was measured over {matching_rows} measurements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Against Our Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use our formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040055451209015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_p([prec_a1, prec_a2])\n",
    "prec_a1 * prec_a2 * fnr_a3 / (prec_a1 * prec_a2 * fnr_a3  + (1-prec_a1) * (1 - prec_a2) * (1 - fnr_a3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty close! If you are not convinced, I invite you to \n",
    "try this out with different authorities with different values of \n",
    "recall and false positive rates.\n",
    "\n",
    "In my next post I will outline a proof.\n",
    "\n",
    "\n",
    "If you have any questions or comments, or believe something is in \n",
    "error, I would love to hear about it in a comment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Footnotes:\n",
    "{{ \"These precisions are assumed to be calculated \n",
    "on a balanced data set with as many true values as false\n",
    "values. If you have an imbalanced dataset, it is suggested\n",
    "to use random downsampling.\"\n",
    "| fndetail: 1\n",
    "}}\n",
    "{{ \"That this last statement is not often\n",
    "true. A good example is two cat classifiers trained on the same\n",
    "pretrained network but with different parameters. In this case,\n",
    "these will not be independent because they will likely start with\n",
    "the same initial features (i.e. given classifier \"A\" predicts that\n",
    "the image is a cat because it has a tail and tall ears, classifier \"B\"\n",
    "will probably also likely classify it as a cat). However, the case of web\n",
    "scraping will often be independent enough. A good example is something\n",
    "that looks for article titles from different metadata, say the `<title>`\n",
    "field and the `<meta key='og:title' content='...'>` meta field.\n",
    "In this case, the  presence of the `meta` field would not directly \n",
    "influence the prediction of the title classifier that looks for the \n",
    "`<title>` field.\"\n",
    "| fndetail: 2}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
